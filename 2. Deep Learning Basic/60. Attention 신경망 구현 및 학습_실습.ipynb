{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"60. Attention 신경망 구현 및 학습_실습.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqsN8QhdWONt","executionInfo":{"status":"ok","timestamp":1630066708091,"user_tz":-540,"elapsed":7585,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}},"outputId":"e6991b4e-6f34-43de-b7fc-fe5dc7d5b40d"},"source":["! pip install konlpy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 104 kB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 46.9 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6aLgihiesfa","executionInfo":{"status":"ok","timestamp":1630066738517,"user_tz":-540,"elapsed":30435,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}},"outputId":"0ae8b5f0-df4f-469c-be94-ef60d32ddfdf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tVCQRS6d4rmj"},"source":["## Attention 신경망 구현 및 학습"]},{"cell_type":"code","metadata":{"id":"ZdWx3q1j4rmn","executionInfo":{"status":"ok","timestamp":1630066740771,"user_tz":-540,"elapsed":2260,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["import random\n","import tensorflow as tf\n","from konlpy.tag import Okt"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jF4eRRMc4rmq"},"source":["## 하이퍼 파라미터"]},{"cell_type":"code","metadata":{"id":"C25rKRiS4rmr","executionInfo":{"status":"ok","timestamp":1630066740774,"user_tz":-540,"elapsed":16,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["EPOCHS = 200\n","NUM_WORDS = 5000"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UM0eFBOJ4rms"},"source":["## Encoder"]},{"cell_type":"code","metadata":{"id":"4uqtW3JU4rmt","executionInfo":{"status":"ok","timestamp":1630066741296,"user_tz":-540,"elapsed":535,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["class Encoder(tf.keras.Model):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n","        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n","        '''\n","        return_sequence=True로하는 이유\n","        : Attention mechanism을 사용할 때 우리가 key와 value는 Encoder에서 나오는 모든 Hidden state 부분을 사용해야 하므로\n","        '''\n","    def call(self, x, training=False, mask=None):\n","        x = self.emb(x)\n","        # embedding 결과 dimension : (batch_size, sequence 길이, embedding feature 수(64))\n","\n","        H, h, c = self.lstm(x)\n","        # H : (batch_size, sequence 길이, LSTM unit 수)\n","        # h : (batch size, LSTM unit 수)\n","        # c : (batch size, LSTM unit 수)\n","        return H, h, c"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkUsQmdI4rmu"},"source":["## Decoder"]},{"cell_type":"code","metadata":{"id":"aj9I7SU74rmv","executionInfo":{"status":"ok","timestamp":1630066793284,"user_tz":-540,"elapsed":4,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 64)\n","        self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n","        self.attention = tf.keras.layers.Attention()\n","        self.dense = tf.keras.layers.Dense(NUM_WORDS, activation='softmax')\n","\n","    def call(self, inputs, training=False, mask=None):\n","        y_, s0, c0, H = inputs\n","        # y_ : shifted labels로 맨 마지막을 제외한 데이터들 (batch size, sequence 길이)\n","        # s0 : 이전 step의 hidden state (batch size, LSTM Unit 개수)\n","        # c0 : 이전 step의 cell state (batch size, LSTM Unit 개수)\n","        # H : Encoder 단의 모든 hidden state를 모은 것 (batch size, sequence길이, LSTM Unit 개수)\n","        \n","        y_ = self.emb(y_)\n","        # embedding 결과 dimension : (batch_size, sequence 길이, embedding feature 수(64))\n","\n","        S, h, c = self.lstm(y_, initial_state=[s0, c0])\n","        # S : (batch_size, sequence 길이, LSTM unit 수)\n","        # h : (batch size, LSTM unit 수)\n","        # c : (batch size, LSTM unit 수)\n","\n","        S_ = tf.concat([s0[:, tf.newaxis, :], S[:, :-1, :]], axis=1)\n","        # S : (batch_size, sequence 길이, LSTM unit 수)\n","\n","        A = self.attention([S_,H])\n","        # A : (batch_size, sequence 길이, LSTM unit 수)\n","        \n","        y = tf.concat([S, A], axis=-1)\n","\n","        return self.dense(y), h, c"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BpdZjyhz4rmx"},"source":["## Seq2seq"]},{"cell_type":"code","metadata":{"id":"1iCWwPHn4rmz","executionInfo":{"status":"ok","timestamp":1630066796584,"user_tz":-540,"elapsed":518,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["class Seq2seq(tf.keras.Model):\n","    def __init__(self, sos, eos):\n","        super(Seq2seq, self).__init__()\n","        self.enc = Encoder()\n","        self.dec = Decoder()\n","        self.sos = sos\n","        self.eos = eos\n","\n","    def call(self, inputs, training=False, mask=None):\n","        if training is True:\n","            x, y = inputs\n","            H, h, c = self.enc(x)\n","            y, _, _ = self.dec((y, h, c, H))\n","            return y\n","        else:\n","            x = inputs\n","            H, h, c = self.enc(x)\n","            y = tf.convert_to_tensor(self.sos)\n","            y = tf.reshape(y, (1, 1))\n","\n","            seq = tf.TensorArray(tf.int32, 64)\n","\n","            for idx in tf.range(64):\n","                y, h, c = self.dec([y, h, c, H])\n","                y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)\n","                y = tf.reshape(y, (1, 1))\n","                seq = seq.write(idx, y)\n","\n","                if y == self.eos:\n","                    break\n","\n","            return tf.reshape(seq.stack(), (1, 64))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6GwX-ba4rm0"},"source":["## 학습, 테스트 루프 정의"]},{"cell_type":"code","metadata":{"id":"dYypPxqH4rm1","executionInfo":{"status":"ok","timestamp":1630066799345,"user_tz":-540,"elapsed":367,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["# Implement training loop\n","@tf.function\n","def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n","    output_labels = labels[:, 1:] # sos 미포함 eos 포함\n","    shifted_labels = labels[:, :-1] # sos 포함 eos 미포함\n","    with tf.GradientTape() as tape:\n","        predictions = model([inputs, shifted_labels], training=True)\n","        loss = loss_object(output_labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    train_loss(loss)\n","    train_accuracy(output_labels, predictions)\n","\n","# Implement algorithm test\n","@tf.function\n","def test_step(model, inputs):\n","    return model(inputs, training=False)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SDZOGyK94rm2"},"source":["## 데이터셋 준비\n"]},{"cell_type":"code","metadata":{"id":"tkWvxpuO4rm3","executionInfo":{"status":"ok","timestamp":1630066760996,"user_tz":-540,"elapsed":19708,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["dataset_file = '/content/drive/MyDrive/패스트캠퍼스/Part4) 딥러닝 3 STEP의 기초/dataset/chatbot_data.csv'  # acquired from 'http://www.aihub.or.kr' and modified\n","okt = Okt()\n","\n","with open(dataset_file, 'r') as file:\n","    lines = file.readlines()\n","    seq = [' '.join(okt.morphs(line)) for line in lines] # morphs : 형태소 분석\n","\n","questions = seq[::2] # 홀수행\n","answers = ['\\t ' + lines for lines in seq[1::2]] # 짝수행\n","# \\t : sos, \\n : eos\n","\n","num_sample = len(questions)\n","\n","perm = list(range(num_sample))\n","random.seed(0)\n","random.shuffle(perm)\n","\n","train_q = list()\n","train_a = list()\n","test_q = list()\n","test_a = list()\n","\n","for idx, qna in enumerate(zip(questions, answers)):\n","    q, a = qna\n","    if perm[idx] > num_sample//5:\n","        train_q.append(q)\n","        train_a.append(a)\n","    else:\n","        test_q.append(q)\n","        test_a.append(a)\n","\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS,\n","                                                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n","\n","tokenizer.fit_on_texts(train_q + train_a)\n","\n","train_q_seq = tokenizer.texts_to_sequences(train_q)\n","train_a_seq = tokenizer.texts_to_sequences(train_a)\n","\n","test_q_seq = tokenizer.texts_to_sequences(test_q)\n","test_a_seq = tokenizer.texts_to_sequences(test_a)\n","\n","x_train = tf.keras.preprocessing.sequence.pad_sequences(train_q_seq,\n","                                                        value=0,\n","                                                        padding='pre',\n","                                                        maxlen=64)\n","y_train = tf.keras.preprocessing.sequence.pad_sequences(train_a_seq,\n","                                                        value=0,\n","                                                        padding='post',\n","                                                        maxlen=65)\n","\n","\n","x_test = tf.keras.preprocessing.sequence.pad_sequences(test_q_seq,\n","                                                       value=0,\n","                                                       padding='pre',\n","                                                       maxlen=64)\n","y_test = tf.keras.preprocessing.sequence.pad_sequences(test_a_seq,\n","                                                       value=0,\n","                                                       padding='post',\n","                                                       maxlen=65)\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(1).prefetch(1024)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AToN-uyf4rm5"},"source":["## 학습 환경 정의\n","### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"]},{"cell_type":"code","metadata":{"id":"XHBzMk254rm6","executionInfo":{"status":"ok","timestamp":1630066803443,"user_tz":-540,"elapsed":384,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}}},"source":["# Create model\n","model = Seq2seq(sos=tokenizer.word_index['\\t'],\n","                eos=tokenizer.word_index['\\n'])\n","\n","# Define loss and optimizer\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Define performance metrics\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u0T_3kHR4rm6"},"source":["## 학습 루프 동작"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"_NbNrFma4rm7","executionInfo":{"status":"ok","timestamp":1630067064004,"user_tz":-540,"elapsed":257538,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}},"outputId":"31275a74-d255-4790-d7e1-d73c6720627d"},"source":["for epoch in range(EPOCHS):\n","    for seqs, labels in train_ds:\n","        train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n","\n","    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n","    print(template.format(epoch + 1,\n","                          train_loss.result(),\n","                          train_accuracy.result() * 100))\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 1, Loss: 3.5171024799346924, Accuracy: 83.14144897460938\n","Epoch 2, Loss: 0.7384456396102905, Accuracy: 90.5349349975586\n","Epoch 3, Loss: 0.5959764122962952, Accuracy: 90.62891387939453\n","Epoch 4, Loss: 0.5666077136993408, Accuracy: 91.15757751464844\n","Epoch 5, Loss: 0.5485181212425232, Accuracy: 91.14191436767578\n","Epoch 6, Loss: 0.5396406054496765, Accuracy: 91.1536636352539\n","Epoch 7, Loss: 0.5366899967193604, Accuracy: 91.16541290283203\n","Epoch 8, Loss: 0.5281073451042175, Accuracy: 91.29072570800781\n","Epoch 9, Loss: 0.5223872661590576, Accuracy: 91.23981475830078\n","Epoch 10, Loss: 0.5095158815383911, Accuracy: 91.28681182861328\n","Epoch 11, Loss: 0.500338077545166, Accuracy: 91.3572998046875\n","Epoch 12, Loss: 0.47368568181991577, Accuracy: 91.502197265625\n","Epoch 13, Loss: 0.46952730417251587, Accuracy: 91.9525375366211\n","Epoch 14, Loss: 0.45724916458129883, Accuracy: 92.10917663574219\n","Epoch 15, Loss: 0.4508518576622009, Accuracy: 92.26973724365234\n","Epoch 16, Loss: 0.44539695978164673, Accuracy: 92.35980224609375\n","Epoch 17, Loss: 0.4411022365093231, Accuracy: 92.44596099853516\n","Epoch 18, Loss: 0.4292958676815033, Accuracy: 92.53211212158203\n","Epoch 19, Loss: 0.42594465613365173, Accuracy: 92.60260009765625\n","Epoch 20, Loss: 0.4203784167766571, Accuracy: 92.65742492675781\n","Epoch 21, Loss: 0.41531193256378174, Accuracy: 92.7239990234375\n","Epoch 22, Loss: 0.40660080313682556, Accuracy: 92.74748992919922\n","Epoch 23, Loss: 0.40510913729667664, Accuracy: 92.78665161132812\n","Epoch 24, Loss: 0.404474139213562, Accuracy: 92.8336410522461\n","Epoch 25, Loss: 0.399138480424881, Accuracy: 92.8806381225586\n","Epoch 26, Loss: 0.3999190032482147, Accuracy: 92.93546295166016\n","Epoch 27, Loss: 0.38783007860183716, Accuracy: 92.93546295166016\n","Epoch 28, Loss: 0.39046505093574524, Accuracy: 92.95895385742188\n","Epoch 29, Loss: 0.38411885499954224, Accuracy: 92.96287536621094\n","Epoch 30, Loss: 0.377555251121521, Accuracy: 93.03337097167969\n","Epoch 31, Loss: 0.3756069540977478, Accuracy: 93.0255355834961\n","Epoch 32, Loss: 0.37302809953689575, Accuracy: 93.11952209472656\n","Epoch 33, Loss: 0.3704839050769806, Accuracy: 93.08036041259766\n","Epoch 34, Loss: 0.3618270456790924, Accuracy: 93.13127136230469\n","Epoch 35, Loss: 0.3612038493156433, Accuracy: 93.15868377685547\n","Epoch 36, Loss: 0.35884425044059753, Accuracy: 93.17826080322266\n","Epoch 37, Loss: 0.35341691970825195, Accuracy: 93.24483489990234\n","Epoch 38, Loss: 0.35049501061439514, Accuracy: 93.30748748779297\n","Epoch 39, Loss: 0.34616944193840027, Accuracy: 93.3583984375\n","Epoch 40, Loss: 0.3426700234413147, Accuracy: 93.33881378173828\n","Epoch 41, Loss: 0.3338969945907593, Accuracy: 93.42888641357422\n","Epoch 42, Loss: 0.33441293239593506, Accuracy: 93.456298828125\n","Epoch 43, Loss: 0.33044278621673584, Accuracy: 93.46021270751953\n","Epoch 44, Loss: 0.32918503880500793, Accuracy: 93.47587585449219\n","Epoch 45, Loss: 0.32096022367477417, Accuracy: 93.49937438964844\n","Epoch 46, Loss: 0.3144415318965912, Accuracy: 93.5463638305664\n","Epoch 47, Loss: 0.3161979913711548, Accuracy: 93.57769775390625\n","Epoch 48, Loss: 0.31272488832473755, Accuracy: 93.62860107421875\n","Epoch 49, Loss: 0.307328999042511, Accuracy: 93.6442642211914\n","Epoch 50, Loss: 0.3031139373779297, Accuracy: 93.73825073242188\n","Epoch 51, Loss: 0.29993680119514465, Accuracy: 93.79307556152344\n","Epoch 52, Loss: 0.29392290115356445, Accuracy: 93.78132629394531\n","Epoch 53, Loss: 0.28820958733558655, Accuracy: 93.8557357788086\n","Epoch 54, Loss: 0.28590869903564453, Accuracy: 93.87531280517578\n","Epoch 55, Loss: 0.27979975938796997, Accuracy: 93.94971466064453\n","Epoch 56, Loss: 0.27859818935394287, Accuracy: 93.96537780761719\n","Epoch 57, Loss: 0.27351686358451843, Accuracy: 94.02803802490234\n","Epoch 58, Loss: 0.2659778892993927, Accuracy: 94.12202453613281\n","Epoch 59, Loss: 0.2585880756378174, Accuracy: 94.30607604980469\n","Epoch 60, Loss: 0.25718772411346436, Accuracy: 94.36481475830078\n","Epoch 61, Loss: 0.253476083278656, Accuracy: 94.41572570800781\n","Epoch 62, Loss: 0.2444777637720108, Accuracy: 94.50187683105469\n","Epoch 63, Loss: 0.23846036195755005, Accuracy: 94.58412170410156\n","Epoch 64, Loss: 0.23190072178840637, Accuracy: 94.80733489990234\n","Epoch 65, Loss: 0.22569496929645538, Accuracy: 94.90523529052734\n","Epoch 66, Loss: 0.22121168673038483, Accuracy: 95.0579605102539\n","Epoch 67, Loss: 0.21653631329536438, Accuracy: 95.21851348876953\n","Epoch 68, Loss: 0.20966283977031708, Accuracy: 95.28508758544922\n","Epoch 69, Loss: 0.2051210254430771, Accuracy: 95.35557556152344\n","Epoch 70, Loss: 0.20135290920734406, Accuracy: 95.42214965820312\n","Epoch 71, Loss: 0.19520007073879242, Accuracy: 95.5670394897461\n","Epoch 72, Loss: 0.1897887885570526, Accuracy: 95.74717712402344\n","Epoch 73, Loss: 0.18392245471477509, Accuracy: 95.96256256103516\n","Epoch 74, Loss: 0.17940860986709595, Accuracy: 96.01346588134766\n","Epoch 75, Loss: 0.17166829109191895, Accuracy: 96.19752502441406\n","Epoch 76, Loss: 0.16710717976093292, Accuracy: 96.30326080322266\n","Epoch 77, Loss: 0.16203273832798004, Accuracy: 96.38158416748047\n","Epoch 78, Loss: 0.15634846687316895, Accuracy: 96.55388641357422\n","Epoch 79, Loss: 0.15176993608474731, Accuracy: 96.69094848632812\n","Epoch 80, Loss: 0.1463320404291153, Accuracy: 96.86325073242188\n","Epoch 81, Loss: 0.13924485445022583, Accuracy: 96.96898651123047\n","Epoch 82, Loss: 0.1338932067155838, Accuracy: 97.08255004882812\n","Epoch 83, Loss: 0.12799587845802307, Accuracy: 97.2274398803711\n","Epoch 84, Loss: 0.12422018498182297, Accuracy: 97.34492492675781\n","Epoch 85, Loss: 0.12238972634077072, Accuracy: 97.48590087890625\n","Epoch 86, Loss: 0.11845291405916214, Accuracy: 97.46631622314453\n","Epoch 87, Loss: 0.11005166172981262, Accuracy: 97.70912170410156\n","Epoch 88, Loss: 0.10434431582689285, Accuracy: 97.88142395019531\n","Epoch 89, Loss: 0.10005378723144531, Accuracy: 98.0067367553711\n","Epoch 90, Loss: 0.0953291654586792, Accuracy: 98.03023529052734\n","Epoch 91, Loss: 0.09028543531894684, Accuracy: 98.19470977783203\n","Epoch 92, Loss: 0.08612068742513657, Accuracy: 98.24169921875\n","Epoch 93, Loss: 0.08184406161308289, Accuracy: 98.40225219726562\n","Epoch 94, Loss: 0.07895217835903168, Accuracy: 98.4453353881836\n","Epoch 95, Loss: 0.07498743385076523, Accuracy: 98.49232482910156\n","Epoch 96, Loss: 0.07283025234937668, Accuracy: 98.65287780761719\n","Epoch 97, Loss: 0.06886264681816101, Accuracy: 98.71945190429688\n","Epoch 98, Loss: 0.06689736247062683, Accuracy: 98.69596099853516\n","Epoch 99, Loss: 0.06312420219182968, Accuracy: 98.83301544189453\n","Epoch 100, Loss: 0.05998741835355759, Accuracy: 98.91917419433594\n","Epoch 101, Loss: 0.05734439939260483, Accuracy: 98.98182678222656\n","Epoch 102, Loss: 0.05536607280373573, Accuracy: 99.03665161132812\n","Epoch 103, Loss: 0.05255642905831337, Accuracy: 99.06797790527344\n","Epoch 104, Loss: 0.0501316599547863, Accuracy: 99.122802734375\n","Epoch 105, Loss: 0.04745519533753395, Accuracy: 99.19721221923828\n","Epoch 106, Loss: 0.04404255002737045, Accuracy: 99.25987243652344\n","Epoch 107, Loss: 0.043014246970415115, Accuracy: 99.32644653320312\n","Epoch 108, Loss: 0.040567297488451004, Accuracy: 99.37734985351562\n","Epoch 109, Loss: 0.03855693340301514, Accuracy: 99.43609619140625\n","Epoch 110, Loss: 0.037097059190273285, Accuracy: 99.47917175292969\n","Epoch 111, Loss: 0.03554762154817581, Accuracy: 99.48699951171875\n","Epoch 112, Loss: 0.03360101953148842, Accuracy: 99.49091339111328\n","Epoch 113, Loss: 0.03152788057923317, Accuracy: 99.53791046142578\n","Epoch 114, Loss: 0.0300300233066082, Accuracy: 99.61231231689453\n","Epoch 115, Loss: 0.02886110544204712, Accuracy: 99.58881378173828\n","Epoch 116, Loss: 0.027419842779636383, Accuracy: 99.63972473144531\n","Epoch 117, Loss: 0.025780251249670982, Accuracy: 99.67105102539062\n","Epoch 118, Loss: 0.025270512327551842, Accuracy: 99.65538787841797\n","Epoch 119, Loss: 0.024667024612426758, Accuracy: 99.6984634399414\n","Epoch 120, Loss: 0.023655451834201813, Accuracy: 99.68672180175781\n","Epoch 121, Loss: 0.023641658946871758, Accuracy: 99.69454956054688\n","Epoch 122, Loss: 0.022060997784137726, Accuracy: 99.73762512207031\n","Epoch 123, Loss: 0.02272813208401203, Accuracy: 99.71021270751953\n","Epoch 124, Loss: 0.021477719768881798, Accuracy: 99.7454605102539\n","Epoch 125, Loss: 0.02019914612174034, Accuracy: 99.74937438964844\n","Epoch 126, Loss: 0.01933523267507553, Accuracy: 99.78462219238281\n","Epoch 127, Loss: 0.018207000568509102, Accuracy: 99.7963638305664\n","Epoch 128, Loss: 0.01733456179499626, Accuracy: 99.77678680419922\n","Epoch 129, Loss: 0.01655684784054756, Accuracy: 99.80419921875\n","Epoch 130, Loss: 0.015314062125980854, Accuracy: 99.81986236572266\n","Epoch 131, Loss: 0.014386877417564392, Accuracy: 99.83161163330078\n","Epoch 132, Loss: 0.013834571465849876, Accuracy: 99.85902404785156\n","Epoch 133, Loss: 0.013588545843958855, Accuracy: 99.85511016845703\n","Epoch 134, Loss: 0.013134563341736794, Accuracy: 99.84727478027344\n","Epoch 135, Loss: 0.01272355392575264, Accuracy: 99.85902404785156\n","Epoch 136, Loss: 0.011796881444752216, Accuracy: 99.8942642211914\n","Epoch 137, Loss: 0.011366878636181355, Accuracy: 99.88252258300781\n","Epoch 138, Loss: 0.011385009624063969, Accuracy: 99.87860107421875\n","Epoch 139, Loss: 0.011171302758157253, Accuracy: 99.88643646240234\n","Epoch 140, Loss: 0.010677153244614601, Accuracy: 99.8942642211914\n","Epoch 141, Loss: 0.010095239616930485, Accuracy: 99.89035034179688\n","Epoch 142, Loss: 0.009705914184451103, Accuracy: 99.8942642211914\n","Epoch 143, Loss: 0.009363099932670593, Accuracy: 99.8942642211914\n","Epoch 144, Loss: 0.008989917114377022, Accuracy: 99.8942642211914\n","Epoch 145, Loss: 0.008865561336278915, Accuracy: 99.91384887695312\n","Epoch 146, Loss: 0.008890348486602306, Accuracy: 99.89818572998047\n","Epoch 147, Loss: 0.0101075554266572, Accuracy: 99.89035034179688\n","Epoch 148, Loss: 0.010849897749722004, Accuracy: 99.83552551269531\n","Epoch 149, Loss: 0.011305882595479488, Accuracy: 99.88252258300781\n","Epoch 150, Loss: 0.01483751367777586, Accuracy: 99.80419921875\n","Epoch 151, Loss: 0.013011296279728413, Accuracy: 99.85118865966797\n","Epoch 152, Loss: 0.011104928329586983, Accuracy: 99.86685180664062\n","Epoch 153, Loss: 0.009929044172167778, Accuracy: 99.88643646240234\n","Epoch 154, Loss: 0.00849836878478527, Accuracy: 99.90601348876953\n","Epoch 155, Loss: 0.007677980232983828, Accuracy: 99.90601348876953\n","Epoch 156, Loss: 0.007985674776136875, Accuracy: 99.88643646240234\n","Epoch 157, Loss: 0.007850589230656624, Accuracy: 99.88252258300781\n","Epoch 158, Loss: 0.00717550702393055, Accuracy: 99.91776275634766\n","Epoch 159, Loss: 0.006794453598558903, Accuracy: 99.902099609375\n","Epoch 160, Loss: 0.006342574022710323, Accuracy: 99.92559814453125\n","Epoch 161, Loss: 0.006040223408490419, Accuracy: 99.92167663574219\n","Epoch 162, Loss: 0.0059806895442306995, Accuracy: 99.92559814453125\n","Epoch 163, Loss: 0.005667403340339661, Accuracy: 99.92559814453125\n","Epoch 164, Loss: 0.0057393708266317844, Accuracy: 99.91384887695312\n","Epoch 165, Loss: 0.005660099443048239, Accuracy: 99.9099349975586\n","Epoch 166, Loss: 0.0053869690746068954, Accuracy: 99.92559814453125\n","Epoch 167, Loss: 0.005524367559701204, Accuracy: 99.9099349975586\n","Epoch 168, Loss: 0.005337221547961235, Accuracy: 99.9099349975586\n","Epoch 169, Loss: 0.0052808839827775955, Accuracy: 99.92167663574219\n","Epoch 170, Loss: 0.005308393854647875, Accuracy: 99.91776275634766\n","Epoch 171, Loss: 0.005104840267449617, Accuracy: 99.90601348876953\n","Epoch 172, Loss: 0.004865884780883789, Accuracy: 99.91776275634766\n","Epoch 173, Loss: 0.004671996459364891, Accuracy: 99.92167663574219\n","Epoch 174, Loss: 0.004698234144598246, Accuracy: 99.9099349975586\n","Epoch 175, Loss: 0.0044245729222893715, Accuracy: 99.91384887695312\n","Epoch 176, Loss: 0.004648162983357906, Accuracy: 99.90601348876953\n","Epoch 177, Loss: 0.00432661222293973, Accuracy: 99.92951202392578\n","Epoch 178, Loss: 0.004282006062567234, Accuracy: 99.91776275634766\n","Epoch 179, Loss: 0.0041832104325294495, Accuracy: 99.92167663574219\n","Epoch 180, Loss: 0.0043166400864720345, Accuracy: 99.9099349975586\n","Epoch 181, Loss: 0.00417752843350172, Accuracy: 99.9099349975586\n","Epoch 182, Loss: 0.003897535614669323, Accuracy: 99.91776275634766\n","Epoch 183, Loss: 0.003805499291047454, Accuracy: 99.92167663574219\n","Epoch 184, Loss: 0.0037652873434126377, Accuracy: 99.90601348876953\n","Epoch 185, Loss: 0.0038388546090573072, Accuracy: 99.9099349975586\n","Epoch 186, Loss: 0.003686521202325821, Accuracy: 99.91384887695312\n","Epoch 187, Loss: 0.0037370880600064993, Accuracy: 99.90601348876953\n","Epoch 188, Loss: 0.0036260022316128016, Accuracy: 99.91384887695312\n","Epoch 189, Loss: 0.003589086700230837, Accuracy: 99.91384887695312\n","Epoch 190, Loss: 0.0035594976507127285, Accuracy: 99.91776275634766\n","Epoch 191, Loss: 0.003490358591079712, Accuracy: 99.9099349975586\n","Epoch 192, Loss: 0.0036741013173013926, Accuracy: 99.91384887695312\n","Epoch 193, Loss: 0.0034471764229238033, Accuracy: 99.92559814453125\n","Epoch 194, Loss: 0.0035721745807677507, Accuracy: 99.91384887695312\n","Epoch 195, Loss: 0.0036262585781514645, Accuracy: 99.9099349975586\n","Epoch 196, Loss: 0.0034816658589988947, Accuracy: 99.92951202392578\n","Epoch 197, Loss: 0.0034655192866921425, Accuracy: 99.91776275634766\n","Epoch 198, Loss: 0.0033176755532622337, Accuracy: 99.92951202392578\n","Epoch 199, Loss: 0.003232804825529456, Accuracy: 99.90601348876953\n","Epoch 200, Loss: 0.0032489660661667585, Accuracy: 99.91384887695312\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ivYmvzKf4rm7"},"source":["## 테스트 루프"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjAT3OJN4rm8","executionInfo":{"status":"ok","timestamp":1630067067727,"user_tz":-540,"elapsed":3731,"user":{"displayName":"이주민","photoUrl":"","userId":"01386847358094111822"}},"outputId":"12fb576e-e7f9-4b9b-8206-533d81782046"},"source":["for test_seq, test_labels in test_ds:\n","    prediction = test_step(model, test_seq)\n","    test_text = tokenizer.sequences_to_texts(test_seq.numpy())\n","    gt_text = tokenizer.sequences_to_texts(test_labels.numpy())\n","    texts = tokenizer.sequences_to_texts(prediction.numpy())\n","    print('_')\n","    print('q: ', test_text)\n","    print('a: ', gt_text)\n","    print('p: ', texts)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["_\n","q:  ['여기 기프티콘 되죠 \\n']\n","a:  ['\\t 네 현금영수증 해드릴까 요 \\n']\n","p:  ['아메리카노 나오면 진동 벨 로 알려 드리겠습니다 \\n']\n","_\n","q:  ['네 에 테이크 아웃 도 가능한가요 \\n']\n","a:  ['\\t 네 로 오시 면 테이크 아웃 잔 에 담아 드려요 \\n']\n","p:  ['네 저기 서 직접 가져오시면 됩니다 \\n']\n","_\n","q:  ['아메리카노 톨 사이즈 로 주세요 \\n']\n","a:  ['\\t 따뜻한 거 로 드릴 까요 \\n']\n","p:  ['드시고 가시나요 \\n']\n","_\n","q:  ['진동 을 따로 주시나요 \\n']\n","a:  ['\\t 주 번호 로 드리겠습니다 \\n']\n","p:  ['네 카드 카드 카드 드릴게요 \\n']\n","_\n","q:  ['자리 있나요 \\n']\n","a:  ['\\t 네 있습니다 \\n']\n","p:  ['아니요 치즈케이크 는 지금 없어요 \\n']\n","_\n","q:  ['그럼 루이보스 밀크 티 하나 \\n']\n","a:  ['\\t 네 알겠습니다 \\n']\n","p:  ['네 이 쪽 에 있습니다 \\n']\n","_\n","q:  ['다음 에 무료 로 하고 엔 도장 찍어주세요 \\n']\n","a:  ['\\t 네 \\n']\n","p:  ['아메리카노 가격 과 아이스 벨 로 주문 한 드릴 까요 \\n']\n","_\n","q:  ['아메리카노 한 잔 에 얼마 죠 \\n']\n","a:  ['\\t 입니다 \\n']\n","p:  ['4100원 입니다 \\n']\n","_\n","q:  ['얼마나 \\n']\n","a:  ['\\t 바로 만들어 드릴게요 \\n']\n","p:  ['10분 정도 걸려요 \\n']\n","_\n","q:  ['카푸치노 는 로 주시 고 아메리카노 는 로 \\n']\n","a:  ['\\t 네 더 없으세요 \\n']\n","p:  ['드시고 가실 건가 요 \\n']\n","_\n","q:  ['아메리카노 는 어떤 종류 가 있나요 \\n']\n","a:  ['\\t 디카 페인 과 기본 아메리카노 2 종류 있습니다 \\n']\n","p:  ['네 유효 에 담아 개 드리겠습니다 \\n']\n","_\n","q:  ['카카오 페이 로 결제 가능한가요 \\n']\n","a:  ['\\t 네 가능합니다 \\n']\n","p:  ['네 자몽 에 이드 없어요 \\n']\n","_\n","q:  ['오늘 의 커피 는 커피 로 하나요 맛 이 \\n']\n","a:  ['\\t 아 네 오늘 은 과테말라 커피 입니다 \\n']\n","p:  ['아메리카노 아메리카노 사이즈 는 어떤 걸 로 드릴 까요 \\n']\n","_\n","q:  ['머핀 은 뭐 가 제일 \\n']\n","a:  ['\\t 블루베리 머핀 이 잘 나갑니다 \\n']\n","p:  ['네 가능합니다 \\n']\n","_\n","q:  ['현금 영수증 해주세요 \\n']\n","a:  ['\\t 네 번호 찍어주세요 \\n']\n","p:  ['네 번호 찍어주세요 \\n']\n","_\n","q:  ['둘 다 톨 사이즈 로 주세요 \\n']\n","a:  ['\\t 여기 서 드시고 요 \\n']\n","p:  ['할인 서 에 만 해드리겠습니다 \\n']\n","_\n","q:  ['아이스 아메리카노 한 잔 가능한가요 \\n']\n","a:  ['\\t 네 가능합니다 \\n']\n","p:  ['아메리카노 아메리카노 아메리카노 아메리카노 아이스 아메리카노 로 아이스 아메리카노 로 한 한 선택 \\n']\n","_\n","q:  ['아이스 아메리카노 에 샷 이 몇 개 \\n']\n","a:  ['\\t 아이스 아메리카노 에 샷 은 개 \\n']\n","p:  ['아메리카노 치즈케이크 는 다 다 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 음료 말씀 말씀 음료 음료 말씀 말씀 말씀 말씀 음료 음료 음료 말씀 말씀 이 5000원 디카 이 이 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노 프라푸치노']\n","_\n","q:  ['카페라테 한 잔 주세요 \\n']\n","a:  ['\\t 카페라테 따뜻한 걸 로 드릴 까요 \\n']\n","p:  ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n","_\n","q:  ['아니요 \\n']\n","a:  ['\\t 네 더 필요하신 건 없으신 가요 \\n']\n","p:  ['10분 정도 걸려요 \\n']\n","_\n","q:  ['네 찍어주세요 \\n']\n","a:  ['\\t 네 주문 딸기 스무디 와 쿠키 드릴게요 \\n']\n","p:  ['더 필요한 건 없으신 가요 \\n']\n","_\n","q:  ['시즌 메뉴 오늘 도 가능한가요 \\n']\n","a:  ['\\t 네 시즌 메뉴 가능합니다 \\n']\n","p:  ['아뇨 매장 에서는 포인트 적립 사용 사용 입니다 \\n']\n","_\n","q:  ['시즌 메뉴 와 함께 되어 있는 세트 메뉴 가 있나요 \\n']\n","a:  ['\\t 네 치즈 케이크 와 시즌 메뉴 두 잔 으로 세트 메뉴 있습니다 \\n']\n","p:  ['네 그건 시즌 한정 메뉴 라 겨울 에는 판매 하지 않습니다 \\n']\n","_\n","q:  ['라테 에 우유 두 도 변경 가능한가요 \\n']\n","a:  ['\\t 네 라테 에 두유 로 변경 가능합니다 \\n']\n","p:  ['루이보스 차 나 밀크 티 종류 는 적립 가능해요 \\n']\n","_\n","q:  ['네 먹고 갈 거 예요 \\n']\n","a:  ['\\t 카드 여기 주세요 \\n']\n","p:  ['할인 카드 있으신 가요 \\n']\n","_\n","q:  ['카페인 이 음료 있나요 \\n']\n","a:  ['\\t 티 음료 와 스무디 에는 카페인 이 않습니다 \\n']\n","p:  ['와이파이 매장 이 드실 가 면 사용 에 있습니다 \\n']\n","_\n","q:  ['딸기스무디 랑 키위 스무디 는 생 과일 인가요 \\n']\n","a:  ['\\t 딸기 는 키위 는 생 과일 을 사용 하고 있습니다 \\n']\n","p:  ['베이글 과 말씀 잔 잔 맛 잔 아이스 로 드릴 테 니 우선 는 있습니다 \\n']\n","_\n","q:  ['그럼 딸기 스무디 하나 주세요 \\n']\n","a:  ['\\t 드시고 가시나요 \\n']\n","p:  ['따뜻한 은 아이스 카페라테 한 잔 드릴 까요 \\n']\n","_\n","q:  ['아메리카노 한 잔이요 \\n']\n","a:  ['\\t 아이스 아메리카노 로 드릴 까요 \\n']\n","p:  ['아이스 로 드릴 까요 \\n']\n","_\n","q:  ['네 도 같이 \\n']\n","a:  ['\\t 네 아메리카노 4000원 입니다 \\n']\n","p:  ['네 번호 입력 건가 요 \\n']\n","_\n","q:  ['디카 페인 아이스 아메리카노 한 잔 주세요 \\n']\n","a:  ['\\t 디카 페인 아이스 아메리카노 는 기존 금액 에 300원 추가 되는데 괜찮으신 가요 \\n']\n","p:  ['네 더 필요한 건 없으세요 \\n']\n","_\n","q:  ['커피 음료 것 뭐 가 있나요 \\n']\n","a:  ['\\t 스무디 와 주스 있습니다 \\n']\n","p:  ['네 초코 가능합니다 \\n']\n","_\n","q:  ['주스 어떤 종류 있나요 \\n']\n","a:  ['\\t 딸기 주스 주스 주스 가 있습니다 \\n']\n","p:  ['네 고객 님 시럽 은 왼쪽 가요 \\n']\n","_\n","q:  ['플랫 화이트 라지 로 주세요 \\n']\n","a:  ['\\t 네 \\n']\n","p:  ['총 화이트 과 카페라테 보다 우유 양 이 좀 \\n']\n","_\n","q:  ['네 레드 벨벳 케이크 주세요 \\n']\n","a:  ['\\t 음료 는 뭘 로 드릴 까요 \\n']\n","p:  ['휘핑크림 올려 드릴 까요 \\n']\n","_\n","q:  ['네 먹고 갈 거 예요 \\n']\n","a:  ['\\t 유리잔 괜찮으세요 \\n']\n","p:  ['할인 카드 있으신 가요 \\n']\n","_\n","q:  ['따뜻한 밀크 티 주세요 \\n']\n","a:  ['\\t 네 \\n']\n","p:  ['아메리카노 아메리카노 사이즈 는 뭘 로 주문 가능합니다 \\n']\n","_\n","q:  ['음료 얼마나 하나요 \\n']\n","a:  ['\\t 10분 정도 주시 면 됩니다 \\n']\n","p:  ['아니요 화이트 따뜻한 거 에서 불가능합니다 \\n']\n","_\n","q:  ['아이스 아메리카노 한잔 얼마 인가요 \\n']\n","a:  ['\\t 4500원 입니다 \\n']\n","p:  ['500원 추가 하면 가능합니다 \\n']\n","_\n","q:  ['현금영수증 번호 \\n']\n","a:  ['\\t 네 \\n']\n","p:  ['네 드시고 가시나요 \\n']\n","_\n","q:  ['이 카드 로 결제 해주세요 \\n']\n","a:  ['\\t 네 결제 도 와 드릴게요 \\n']\n","p:  ['네 알겠습니다 \\n']\n","_\n","q:  ['주문 한 게 다 안 \\n']\n","a:  ['\\t 주 번호 가 몇 이 죠 \\n']\n","p:  ['네 알겠습니다 \\n']\n","_\n","q:  ['을 \\n']\n","a:  ['\\t \\n']\n","p:  ['죄송합니다만 페퍼민트 는 재료 로 에 드릴게요 \\n']\n","_\n","q:  ['베이글 은 얼마 인가요 \\n']\n","a:  ['\\t 베이글 은 2000원 입니다 \\n']\n","p:  ['베이글 과 동일하게 2000원 입니다 \\n']\n","_\n","q:  ['지금 되나요 \\n']\n","a:  ['\\t 는 계절 메뉴 라 지금 은 판매 하지 않습니다 \\n']\n","p:  ['네 고객 님 포인트 적립 가능하세요 \\n']\n","_\n","q:  ['바닐라 라테 는 따뜻하게 주세요 \\n']\n","a:  ['\\t 네 적립 이나 할인 카드 있으세요 \\n']\n","p:  ['바닐라 라테 따뜻한 거 요 \\n']\n","_\n","q:  ['테이크 아웃 으로 부탁드립니다 \\n']\n","a:  ['\\t 결제 는 이 쪽 에서 도 와 드릴게요 \\n']\n","p:  ['네 고객 님 포인트 적립 하시겠어요 \\n']\n","_\n","q:  ['혹시 테이크 아웃 잔 에 수 있나요 \\n']\n","a:  ['\\t 테이크 아웃 하시는 건가 요 \\n']\n","p:  ['네 바닥 청소 도 해야 드릴게요 \\n']\n","_\n","q:  ['아메리카노 하나 는 샷 추가 해주세요 \\n']\n","a:  ['\\t 아메리카노 는 둘 다 따뜻한 걸 로 드릴 까요 \\n']\n","p:  ['네 사이즈 는 와 한 를 를 불가능합니다 \\n']\n","_\n","q:  ['쿠폰 찍어주세요 \\n']\n","a:  ['\\t 네 찍어 드릴게요 \\n']\n","p:  ['10 개 다모아 오시 면 커피한잔 드려요 \\n']\n","_\n","q:  ['주문 할게요 \\n']\n","a:  ['\\t 어떤 거 드릴 까요 \\n']\n","p:  ['네 어떤 걸 로 하시겠습니까 \\n']\n","_\n","q:  ['파나요 \\n']\n","a:  ['\\t 는 계절 지금 은 \\n']\n","p:  ['자리 에 앉아 계시 면 가져다 드리겠습니다 \\n']\n","_\n","q:  ['그럼 겨울 메뉴 뭐 가 \\n']\n","a:  ['\\t 겨울 엔 감귤 라테 가 제일 많이 나가요 \\n']\n","p:  ['네 커피 가 많이 진할 면 있습니다 \\n']\n","_\n","q:  ['네 결제 는 카드 로 할게요 \\n']\n","a:  ['\\t 네 결제 완료 되었습니다 \\n']\n","p:  ['네 카드 받았습니다 \\n']\n","_\n","q:  ['둘 다 사이즈 로 할게요 \\n']\n","a:  ['\\t 네 결제 는 어떤 것 으로 도 와 드릴 까요 \\n']\n","p:  ['주문 도 하셨나요 \\n']\n","_\n","q:  ['기프티콘 으로 결제 할게요 \\n']\n","a:  ['\\t 네 그럼 쿠폰 저 \\n']\n","p:  ['저 한테 보여주시고 제 가 확인 버튼 누르면 돼요 \\n']\n","_\n","q:  ['녹차 라테 1 잔 주세요 \\n']\n","a:  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n","p:  ['휘핑크림 올려 드릴 까요 \\n']\n","_\n","q:  ['네 그럼 휘핑크림 추가 해서 주세요 \\n']\n","a:  ['\\t 네 녹차 라테 에 휘핑크림 추가 해서 4500원 입니다 \\n']\n","p:  ['네 더 필요한 건 없으신 가요 \\n']\n","_\n","q:  ['브레드 종류 는 뭐 가 있나요 \\n']\n","a:  ['\\t 허니 브레드 와 갈릭 치즈 브레드 가 있습니다 \\n']\n","p:  ['네 고객 님 티 종류 다 아이스 가능합니다 \\n']\n","_\n","q:  ['생크림 이 건 어떤 건가 요 \\n']\n","a:  ['\\t 허니 브레드 입니다 \\n']\n","p:  ['네 2 층 에 자리 많아요 \\n']\n","_\n","q:  ['네 그렇게 만들어 주세요 \\n']\n","a:  ['\\t 더 필요한 건 없으세요 \\n']\n","p:  ['더 필요한 건 없으세요 \\n']\n","_\n","q:  ['여기 있습니다 \\n']\n","a:  ['\\t 네 확인 되셨고 되면 진동 벨 거 예요 \\n']\n","p:  ['손님 지금 15000 포인트 있으신 데 사용 해 드릴 까요 \\n']\n","_\n","q:  ['핫초코 한 잔 아메리카노 사이 즈 업 한 잔 하면 얼마 인가요 \\n']\n","a:  ['\\t 입니다 \\n']\n","p:  ['9500원 입니다 \\n']\n","_\n","q:  ['주스 는 다른 건 없나요 \\n']\n","a:  ['\\t 그럼 에 라테 추천 \\n']\n","p:  ['네 있습니다 \\n']\n","_\n","q:  ['그건 \\n']\n","a:  ['\\t 네 만 따듯 해 요 \\n']\n","p:  ['자리 에 앉아 계시 면 가져다 드리겠습니다 \\n']\n","_\n","q:  ['통신사 할인 되죠 \\n']\n","a:  ['\\t 네 300원 할인 됩니다 \\n']\n","p:  ['네 더 필요한 건 없으세요 \\n']\n","_\n","q:  ['매장 에서 언제 까지 영업 하시나요 \\n']\n","a:  ['\\t 오후 10시 까지 영업 입니다 \\n']\n","p:  ['와이파이 암호 는 2 개 이상 부터 가능해요 \\n']\n","_\n","q:  ['아니요 그냥 주세요 \\n']\n","a:  ['\\t 결제 해드릴게요 \\n']\n","p:  ['카페모카 5천 원 입니다 \\n']\n","_\n","q:  ['가격 안 되나요 \\n']\n","a:  ['\\t 한 해드릴게요 \\n']\n","p:  ['네 이 쪽 에 있습니다 \\n']\n","_\n","q:  ['카페라테 한잔 주세요 \\n']\n","a:  ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n","p:  ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n","_\n","q:  ['네 차가운 걸 로 주세요 \\n']\n","a:  ['\\t 4500원 입니다 \\n']\n","p:  ['따뜻한 걸 로 드릴 까요 \\n']\n","_\n","q:  ['어떤 게 괜찮아요 \\n']\n","a:  ['\\t 이나 원두 를 하시는 게 아니면 예 가체 많이 추천 \\n']\n","p:  ['와이파이 암호 는 가나다라 입니다 \\n']\n","_\n","q:  ['그럼 추천 치즈 케이크 도 같이 주세요 \\n']\n","a:  ['\\t 네 매장 에서 드시고 가시나요 \\n']\n","p:  ['네 총 적립 머핀 기계 드리겠습니다 \\n']\n","_\n","q:  ['그리고 휘핑크림 은 에스프레소 크림 으로 \\n']\n","a:  ['\\t 결제 는 어떻게 해드릴까 요 \\n']\n","p:  ['아메리카노 치즈케이크 는 어떤 걸 로 주문 넣어 드릴 까요 \\n']\n","_\n","q:  ['지금 도 할인 하나요 \\n']\n","a:  ['\\t 네 10시 까지 하고 있습니다 \\n']\n","p:  ['네 네 더 필요한 거 있으세요 \\n']\n","_\n","q:  ['그럼 와 아이스 아메리카노 로 할게요 \\n']\n","a:  ['\\t 더 필요하신 건 없나요 \\n']\n","p:  ['네 잠시 만 기다려주세요 \\n']\n","_\n","q:  ['네 할인 적립 은 \\n']\n","a:  ['\\t 네 바코드 \\n']\n","p:  ['네 진동 벨 울리면 픽업 테이블 로 와주세요 \\n']\n","_\n","q:  ['초코 프라푸치노 주세요 \\n']\n","a:  ['\\t 휘핑 올려 드릴 까요 \\n']\n","p:  ['네 아이스 프라푸치노 몇 잔 드릴 까요 \\n']\n","_\n","q:  ['시럽 도 가 \\n']\n","a:  ['\\t 드시고 가시나요 \\n']\n","p:  ['고객 님 시럽 은 왼쪽 에 보시 면 있습니다 \\n']\n","_\n","q:  ['둘 다 사이즈 로 주세요 \\n']\n","a:  ['\\t 드시고 가시나요 \\n']\n","p:  ['드시고 가시나요 \\n']\n","_\n","q:  ['마시다가 갈 건데 테이크아웃 으로 주세요 \\n']\n","a:  ['\\t 상 매장 에서는 머그컵 으로 드리고 있어요 \\n']\n","p:  ['부드러워서 사이즈 가 괜찮으세요 \\n']\n","_\n","q:  ['나갈 때 테이크아웃 컵 으로 수 있나요 \\n']\n","a:  ['\\t 네 그렇게 해드릴게요 \\n']\n","p:  ['네 커피 는 많이 는 품절 되었습니다 \\n']\n","_\n","q:  ['아메리카노 두 잔 한잔 주세요 \\n']\n","a:  ['\\t 드시고 가실 건가 요 \\n']\n","p:  ['매장 에서 드시고 가시나요 \\n']\n","_\n","q:  ['얼마나 하나요 \\n']\n","a:  ['\\t 5분 정도 \\n']\n","p:  ['10분 정도 걸려요 \\n']\n","_\n","q:  ['포인트 적립 해주세요 \\n']\n","a:  ['\\t 네 번호 입력 부탁드립니다 \\n']\n","p:  ['네 \\n']\n","_\n","q:  ['네 번호 로 할게요 \\n']\n","a:  ['\\t 네 에 번호 \\n']\n","p:  ['주차 는 하셨나요 \\n']\n","_\n","q:  ['아 포인트 포인트 사용 해주세요 \\n']\n","a:  ['\\t 네 고객 님 포인트 총 있으신 데 사용 도 와 드리겠습니다 \\n']\n","p:  ['네 가능해요 \\n']\n","_\n","q:  ['톨 사이즈 로 주문 할게요 \\n']\n","a:  ['\\t 네 계산 도 와 드리겠습니다 \\n']\n","p:  ['아메리카노 따뜻한 건가 요 \\n']\n","_\n","q:  ['아메리카노 사이즈 가능한가요 \\n']\n","a:  ['\\t 네 500원 만 추가 하시면 가능하십니다 \\n']\n","p:  ['아니요 한 사이즈 로만 판매 하고 있습니다 \\n']\n","_\n","q:  ['사이 즈 업 해서 주세요 \\n']\n","a:  ['\\t 네 결제 는 어떻게 도 와 드릴 까요 \\n']\n","p:  ['네 아이스 프라푸치노 몇 잔 드릴 까요 \\n']\n","_\n","q:  ['커피 는 텀블러 에 담아주세요 \\n']\n","a:  ['\\t 네 텀블러 할인 4000원 결제 도 와 드리겠습니다 \\n']\n","p:  ['텀블러 할인 300원 같이 해드릴게요 \\n']\n","_\n","q:  ['아니요 아이스 로 주세요 \\n']\n","a:  ['\\t 드시고 가실 건가 요 \\n']\n","p:  ['레귤러 사이즈 로 괜찮으세요 \\n']\n","_\n","q:  ['테이크아웃 할게요 \\n']\n","a:  ['\\t 지금 중 인데 케이크 주문 하시면 아메리카노 한잔 로 드려요 \\n']\n","p:  ['네 알겠습니다 \\n']\n","_\n","q:  ['현금 결제 가 안 \\n']\n","a:  ['\\t 현금 은 에서 주문 도 와 드리겠습니다 \\n']\n","p:  ['네 4500원 에 있습니다 \\n']\n","_\n","q:  ['포인트 적립 되나요 \\n']\n","a:  ['\\t 번호 포인트 적립 도 와 드리고 있어요 \\n']\n","p:  ['네 가능합니다 \\n']\n","_\n","q:  ['포인트 적립 할게요 \\n']\n","a:  ['\\t 네 결제 되셨습니다 \\n']\n","p:  ['네 카드 받았습니다 \\n']\n","_\n","q:  ['티라미수 는 있나요 \\n']\n","a:  ['\\t 네 티라미수 는 있습니다 \\n']\n","p:  ['네 자몽 차는 있습니다 \\n']\n","_\n","q:  ['네 현금영수증 해주세요 \\n']\n","a:  ['\\t 네 드시고 가시나요 \\n']\n","p:  ['네 더 필요하신 건 없으세요 \\n']\n","_\n","q:  ['샷 추가 해주세요 \\n']\n","a:  ['\\t 네 알겠습니다 \\n']\n","p:  ['따뜻한 거 맞으세요 \\n']\n","_\n","q:  ['얼마 에요 \\n']\n","a:  ['\\t 만 원 입니다 \\n']\n","p:  ['총 7000원 입니다 \\n']\n","_\n","q:  ['아이스 아메리카노 랑 샌드위치 주세요 \\n']\n","a:  ['\\t 10시 에 세트 할인 가능하세요 \\n']\n","p:  ['아이스 아메리카노 따뜻하게 드릴 까요 \\n']\n"],"name":"stdout"}]}]}